\chapter{Implementation}\section{Integration with NPPC data repository}Initial implementation and spike work was conducted with the assumption that a network connection to the NPPC data repository would be established and maintained by the system. After a meeting with Dr Colin Sauze, it became apparent that the project would be hosted on a machine at the NPPC and that the hosting environment (discussed in section~\ref{hosting}) would have the data repository mounted as a network drive as default. This meant that the system could treat the repository as a local drive on the hosting environment, removing the requirement for the system to manage a network connection to the repository. In order to avoid transferring and re-hosting images from the repository it was necessary to add the repository as a static content resource within Spring such that the Tomcat web server driving the system could serve the images. This was simple to achieve within Spring by providing a custom implementation of the \texttt{WebMvcAutoConfigurationAdapter} class and its \texttt{addResourceHandlers} method where a file location could be defined as a resource and assigned a URL based resource handler. In the case of the images within the repository, they are handled from the base URL \texttt{/images}.The initial design involved using a recursive method to parse the various directories within the repository and create the various plants for an experiment from the directory structure. Performance was a noticeable issue with experiment initialisation taking an unreasonable amount of time to read plants from the repository. During troubleshooting this performance issue, an iterative approach that was tightly coupled to the file system structure was implemented for comparison purposes. This iterative approach was over twice as quick as all the tested and recommended recursive methods especially when checks on specific directories were required such as those needed to check for filtered image modalities.It was decided that the iterative approach offers enough of a difference in performance for the tight-coupling to be a fair trade off. However, changes were made to the directory structure of the repository soon after the implementation of the iterative approach. Discussions followed with Dr Colin Sauze who has oversight of the repository and it was confirmed that no further changes were planned since utilities he had written to interact with the repository were now also tightly coupled to the new structure. In the event that further changes need to be made, a recursive solution is provided within the source code (commented) of the project ensuring the project can function without much in the way of code change.\section{Graphing System}As part of the planning and design phases for the graphing based functionality in the system it was necessary to investigate and decide upon a framework or library that would allow the generation and display of graph based visualisations within the system. Having selected Plotly.js it was necessary to integrate the library into the system. Being a Javascript library made this fairly simple. However, in order to allow the user to configure certain settings that control the way the graphs are generated, a number of helper functions had to be implemented in Javascript to provide a simple interface onto the Plotly library from within the Graph pages on the site. The flexibility of Plotly and the wide range of graphing options that it provides meant that implementing a means for the user to configure it completely was impractical. The pages in the system are built using a responsive CSS design (responsive functionality provided by Bootstrap), in order to be compatible and maintain the responsive resizing of elements within the page, the graphs generated via Plotly would resize in proportion to the html element in which they were positioned. Unfortunately, even though the documentation for Plotly mentions dynamic resizing it was not possible to get the feature to work correctly within the system and the exact reason for this is still unknown. The result of this is that each graph generated currently has fixed dimensions. Having integrated the Plotly library into the system, the next implementation step was to provide it with data. This was achieved by providing a number of asynchronous Javascript functions that would send the user selected parameters for the graph to a method in the \texttt{GraphsPageController} class. The \texttt{GraphsPageController} takes advantage of the convenience annotation \texttt{@ResponseBody} provided by the Spring framework that converts the object returned by a controller class (specified using the \texttt{@Controller} annotation) into JSON format. This made the data returned to the asynchronous function compatible with Plotly and could be passed directly to the function creating the graph. The graph data itself is retrieved by the \texttt{GraphingManager} class using the user selected attributes to query the data layer for resulting Plants or PlantDays. Implementing functionality that would return plant results into the graph page when clicking on data points in the graph provided to be more complex than initially estimated. The added complexity was a direct result of a separate design decision to move metadata attributes to their own table within the database (discussed in section~\ref{db}). The difficulty was in building the correct query in JPA query language in order to return plants based on the key/value attribute pairs for two separate attributes, gaining familiarity with the syntax and experimenting with the various join query options eventually solved the issue.\section{Domain model implementation and ORM}Talk about looping references and stack overflows? Laze/eager fetch? @Transactional?  Session management\section{Data Import}Implementing the design for the experiment data import system was fairy straightforward. The design called for the use of custom annotations in the header of a source CSV file in order to efficiently route the contained data correctly. When the header of the CSV file is parsed, the header is separated from the body of the file, the columns corresponding to each annotation type have their index number added to a list corresponding to that type. For example, if the second column in the header was annotated with the \texttt{\{\{plant-t\}\}} (see section~\ref{dataimp} for annotation details) annotation, then the index `2' would be added to the list holding plant tag column indices, further columns with the same annotation would have their indices added to the same list. In a similar way, the column containing the identifying barcode for the Plants is identified and its index saved. The body of the experiment CSV file is processed line by line. A line in the file is represented by a list of String objects. For each line in the file, the identifying barcode is extracted by reading the value in the line list occupying the index corresponding to the barcode, the correct plant can then be found in the database. A similar approach is taken for the other column types, essentially their values are extracted by directly reading the value in the line that corresponds to the index in a given list. Listing~\ref{lst:dataIm} shows how this is achieved for plant data attributes, the indices corresponding to plant attribute columns are held in the list \texttt{plantAttribIndex}, for each index in this list the values are read directly from the line. In this instance the key/value attribute pair consists of the header and the column value, this attribute pair is then saved into the plant corresponding to the barcode found in the line.\lstjava\lstinputlisting[label={lst:dataIm},caption=Detail of routing data during import]{sourceCode/mySnippets/impl/header.java}Issues encountered during the implementation of this feature were mostly generic issues concerning the reading in of data from file, notably date formatting and certain special characters causing issues when attempting to display them as attributes or tags in the front end of the site since Spring and the page templating framework Thymeleaf have some inbuilt special character sanitisation.. \section{IBERS hosted environment}\label{hosting}As discussed in section~\ref{framework}, a consideration during the selection of framework within which the project would be implemented was the number of dependencies it would place on the environment it was hosted. The less dependencies then the more attractive the framework since this directly affects the time required to configure and maintain the environment. This project required that three dependencies be present on a given environment to enable the system to function, the Java runtime environment, MySQL database server and the Apache Maven build tool which is bundled into and required to run Spring-Boot applications. Initially the Java version used for the project was version 8, however, it was more convenient for the NPPC to provide a server with Java version 7 forcing the change in targeted language level. Fortunately, this occurred sufficiently early in the implementation that not much of the codebase was dependant on new features not available in the version 7 Java runtime and the required changes were small and trivial.The provided hosting environment was provisioned and set up by Dr Colin Sauze, the data manager at the NPPC. The hosting environment is a virtual machine running Ubuntu v14.04 hosted on a Intel CPU based server with 8GB of RAM. It is hosted with the Universities firewall and as such is only accessible from within the University network (or via VPN). The network restriction meant that the deployment of a release build of the system could not be completed via the project continuous integration platform. The deployment process was not fully automated for the project. For a given release version, the source code would be checked out from the version control repository and the system rebuilt and restarted on the server itself. Sine this required only three commands at the end of each week to be entered into the system terminal, it was deemed that automation was not necessary.